from fastai.vision.all import *
import timm
import torch
import matplotlib.pyplot as plt
from pathlib import Path
from torch.nn import CrossEntropyLoss
import json

def safe_save_model(learner, filename, model_dir):
    """LÆ°u mÃ´ hÃ¬nh an toÃ n Ä‘á»ƒ trÃ¡nh lá»—i CUDA khi pickling."""
    device = next(learner.model.parameters()).device
    learner.model.cpu()
    learner.export(model_dir / f"{filename}.pkl")
    learner.model.to(device)

def plot_training_history(train_losses, test_losses, train_accs, test_accs, save_path):
    """Váº½ biá»ƒu Ä‘á»“ Accuracy vÃ  Loss cá»§a Train vÃ  Test."""
    epochs = range(1, len(train_losses) + 1)

    # Accuracy Plot
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, train_accs, label='Train Accuracy', color='blue')
    plt.plot(epochs, test_accs, label='Test Accuracy', color='green')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Model Accuracy')
    plt.legend()
    plt.grid()
    plt.savefig(save_path / "accuracy_plot.png")
    plt.close()

    # Loss Plot
    plt.figure(figsize=(8, 4))
    plt.plot(epochs, train_losses, label='Train Loss', color='blue')
    plt.plot(epochs, test_losses, label='Test Loss', color='green')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Model Loss')
    plt.legend()
    plt.grid()
    plt.savefig(save_path / "loss_plot.png")
    plt.close()

def evaluate_model(learner, test_path):
    """Cháº¡y mÃ´ hÃ¬nh trÃªn táº­p test vÃ  tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng nhÃ£n."""
    test_files = get_image_files(test_path)
    test_dl = learner.dls.test_dl(test_files)

    preds, _ = learner.tta(dl=test_dl)  # DÃ¹ng TTA Ä‘á»ƒ cáº£i thiá»‡n káº¿t quáº£ test
    labels = [learner.dls.vocab[i] for i in preds.argmax(dim=1)]

    true_counts = {label: 0 for label in learner.dls.vocab}
    total_counts = {label: 0 for label in learner.dls.vocab}

    for file, label in zip(test_files, labels):
        actual_label = file.parent.name
        total_counts[actual_label] += 1
        if actual_label == label:
            true_counts[label] += 1

    accuracies = {label: (true_counts[label] / total_counts[label] * 100) if total_counts[label] > 0 else 0 for label in learner.dls.vocab}

    return accuracies

def main():
    # XÃ¡c Ä‘á»‹nh thÆ° má»¥c gá»‘c
    base_dir = Path(__file__).resolve().parent
    data_path = base_dir / 'data' / 'Training'
    test_path = base_dir / 'data' / 'Testing'
    model_dir = base_dir / 'models'
    model_dir.mkdir(exist_ok=True)

    required_dirs = ['no_tumor', 'glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']
    if not all((data_path / cls).exists() for cls in required_dirs):
        print(f"âš ï¸ Thiáº¿u thÆ° má»¥c dá»¯ liá»‡u! Kiá»ƒm tra láº¡i: {required_dirs}")
        return

    # Táº¡o DataBlock
    brain_tumor = DataBlock(
        blocks=(ImageBlock, CategoryBlock),
        get_items=get_image_files,
        splitter=RandomSplitter(valid_pct=0.2, seed=42),
        get_y=parent_label,
        item_tfms=Resize(256),
        batch_tfms=aug_transforms(
            do_flip=True, flip_vert=True, max_rotate=30,  
            max_zoom=1.2, max_lighting=0.3, max_warp=0.4,
            p_affine=0.75, p_lighting=0.75  
        )
    )

    dls = brain_tumor.dataloaders(data_path, bs=32, num_workers=0)

    print(f"Sá»‘ áº£nh trong train: {len(dls.train_ds)}, validation: {len(dls.valid_ds)}")

    # Khá»Ÿi táº¡o EfficientNet-B5
    learn = vision_learner(dls, "efficientnet_b3", metrics=accuracy, pretrained=True)
    learn.to_fp16()
    learn.model_dir = model_dir

    # Trá»ng sá»‘ loss Æ°u tiÃªn glioma (giáº£m xuá»‘ng 2.0 Ä‘á»ƒ trÃ¡nh overfitting)
    weights = torch.tensor([1.5, 1.0, 1.0, 1.2], dtype=torch.float32).cuda()
    learn.loss_func = LabelSmoothingCrossEntropy(weight=weights)

    print("ğŸ”„ Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Fine-Tuning...")

    best_test_acc = 0
    patience = 10
    patience_counter = 0
    epoch = 0
    max_epochs = 100

    train_losses, test_losses, train_accs, test_accs = [], [], [], []
    log_file = model_dir / "training_log.txt"

    with open(log_file, "w") as log:
        log.write("Epoch | Train Loss | Test Loss | Train Acc | Test Acc\n")
        log.write("-" * 50 + "\n")

        while epoch < max_epochs:
            epoch += 1
            print(f"Epoch {epoch} báº¯t Ä‘áº§u...")

            learn.fit_one_cycle(1, 3e-4)  # Giáº£m learning rate

            train_loss = learn.recorder.losses[-1].item()
            train_acc = learn.recorder.values[-1][1]

            test_acc_dict = evaluate_model(learn, test_path)
            test_acc = sum(test_acc_dict.values()) / len(test_acc_dict)
            test_loss = None  

            train_losses.append(train_loss)
            test_losses.append(test_loss)
            train_accs.append(train_acc)
            test_accs.append(test_acc)

            print(f"Epoch {epoch} - Train Loss: {train_loss:.4f}, Test Acc: {test_acc:.4f}")

            log.write(f"{epoch:<5} | {train_loss:.4f} | N/A | {train_acc:.4f} | {test_acc:.4f}\n")

            if test_acc > best_test_acc:
                best_test_acc = test_acc
                print("ğŸ“¥ LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t...")
                safe_save_model(learn, 'best_model', model_dir)
                patience_counter = 0
            else:
                patience_counter += 1

            if patience_counter >= patience:
                print("â¹ï¸ Dá»«ng training do khÃ´ng cáº£i thiá»‡n liÃªn tiáº¿p.")
                break

    print("ğŸ’¾ LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng...")
    safe_save_model(learn, 'last_model', model_dir)

    plot_training_history(train_losses, test_losses, train_accs, test_accs, model_dir)

    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t
    print("ğŸ” ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn táº­p test...")
    best_model = load_learner(model_dir / "best_model.pkl")
    final_test_acc_dict = evaluate_model(best_model, test_path)

    with open(model_dir / "test_results.json", "w") as f:
        json.dump(final_test_acc_dict, f, indent=4)

    print("âœ… Káº¿t quáº£ test tá»«ng nhÃ£n:")
    for label, acc in final_test_acc_dict.items():
        print(f"ğŸ”¹ {label}: {acc:.2f}%")

if __name__ == '__main__':
    main()
