from fastai.vision.all import *
import timm
import torch
import json
from pathlib import Path

def safe_save_model(learner, filename):
    """LÆ°u mÃ´ hÃ¬nh an toÃ n Ä‘á»ƒ trÃ¡nh lá»—i CUDA khi pickling."""
    device = next(learner.model.parameters()).device
    learner.model.cpu()  # Chuyá»ƒn vá» CPU trÆ°á»›c khi lÆ°u
    learner.export(f"models/{filename}.pkl")  # LÆ°u mÃ´ hÃ¬nh dÆ°á»›i dáº¡ng .pkl
    learner.model.to(device)  # Chuyá»ƒn láº¡i vá» thiáº¿t bá»‹ ban Ä‘áº§u

def evaluate_model(learner, test_path):
    """Cháº¡y mÃ´ hÃ¬nh trÃªn táº­p test vÃ  tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c cá»§a tá»«ng nhÃ£n."""
    test_files = get_image_files(test_path)
    test_dl = learner.dls.test_dl(test_files)
    preds, _ = learner.get_preds(dl=test_dl)
    labels = [learner.dls.vocab[i] for i in preds.argmax(dim=1)]

    # Äáº¿m sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn má»—i nhÃ£n
    true_counts = {label: 0 for label in learner.dls.vocab}
    total_counts = {label: 0 for label in learner.dls.vocab}

    for file, label in zip(test_files, labels):
        actual_label = file.parent.name
        total_counts[actual_label] += 1
        if actual_label == label:
            true_counts[label] += 1

    # TÃ­nh accuracy cá»§a tá»«ng nhÃ£n
    accuracies = {label: (true_counts[label] / total_counts[label] * 100) if total_counts[label] > 0 else 0 for label in learner.dls.vocab}

    return accuracies

def main():
    Path('models').mkdir(exist_ok=True)

    # Äá»‹nh nghÄ©a Ä‘Æ°á»ng dáº«n dá»¯ liá»‡u
    data_path = Path('data/Training')
    test_path = Path('data/Testing')

    # Kiá»ƒm tra xem cÃ¡c thÆ° má»¥c dá»¯ liá»‡u cÃ³ tá»“n táº¡i khÃ´ng
    assert all((data_path/cls).exists() for cls in ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']), \
           "Thiáº¿u má»™t hoáº·c nhiá»u thÆ° má»¥c dá»¯ liá»‡u!"

    # Táº¡o DataBlock vá»›i Augmentation
    brain_tumor = DataBlock(
        blocks=(ImageBlock, CategoryBlock),
        get_items=get_image_files,
        splitter=RandomSplitter(valid_pct=0.2, seed=42),
        get_y=parent_label,
        item_tfms=Resize(224),
        batch_tfms=aug_transforms(
            do_flip=True, flip_vert=True, max_rotate=30.0, 
            max_zoom=1.2, max_lighting=0.2, max_warp=0.2
        )
    )

    # Táº¡o DataLoaders
    dls = brain_tumor.dataloaders(data_path, bs=32, num_workers=0)

    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh ResNet101
    learn = vision_learner(dls, 'resnet101', metrics=accuracy)
    learn.to_fp16()  # Sá»­ dá»¥ng mixed precision Ä‘á»ƒ tÄƒng tá»‘c
    learn.model_dir = Path('models')

    # Huáº¥n luyá»‡n vá»›i Fine-Tuning
    print("ğŸ”„ Huáº¥n luyá»‡n mÃ´ hÃ¬nh vá»›i Fine-Tuning...")
    learn.fine_tune(15, base_lr=3e-4)

    # Biáº¿n Ä‘á»ƒ theo dÃµi mÃ´ hÃ¬nh tá»‘t nháº¥t
    best_val_loss = float('inf')
    best_val_acc = 0
    patience = 10
    patience_counter = 0
    epoch = 0
    max_epochs = 100

    # LÆ°u log training
    log_file = Path("models/training_log.txt")
    with open(log_file, "w") as log:
        log.write("Epoch | Train Loss | Test Loss | Train Acc | Test Acc\n")
        log.write("-" * 50 + "\n")

        while epoch < max_epochs:
            epoch += 1
            print(f"Epoch {epoch} báº¯t Ä‘áº§u...")

            learn.fit_one_cycle(1, 3e-3)

            train_loss = learn.recorder.losses[-1].item()
            train_acc = learn.recorder.values[-1][1]

            # ÄÃ¡nh giÃ¡ trÃªn táº­p test
            test_acc_dict = evaluate_model(learn, test_path)
            test_acc = sum(test_acc_dict.values()) / len(test_acc_dict)  # Trung bÃ¬nh accuracy
            test_loss = None  # KhÃ´ng cÃ³ test loss vÃ¬ fastai khÃ´ng tÃ­nh

            train_loss_str = f"{train_loss:.4f}"
            test_loss_str = "N/A"
            train_acc_str = f"{train_acc:.4f}"
            test_acc_str = f"{test_acc:.4f}"

            print(f"Epoch {epoch} - Train Loss: {train_loss_str}, Test Acc: {test_acc_str}")

            log.write(f"{epoch:<5} | {train_loss_str} | {test_loss_str} | {train_acc_str} | {test_acc_str}\n")

            if test_acc > best_val_acc:
                best_val_acc = test_acc
                print("ğŸ“¥ LÆ°u mÃ´ hÃ¬nh tá»‘t nháº¥t...")
                safe_save_model(learn, 'best_model')
                patience_counter = 0
            else:
                patience_counter += 1

            if patience_counter >= patience:
                print("â¹ï¸ Dá»«ng training do khÃ´ng cáº£i thiá»‡n liÃªn tiáº¿p.")
                break

    print("ğŸ’¾ LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng...")
    safe_save_model(learn, 'last_model')

    # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t sau training
    print("ğŸ” ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh tá»‘t nháº¥t trÃªn táº­p test...")
    best_model = load_learner("models/best_model.pkl")
    final_test_acc_dict = evaluate_model(best_model, test_path)

    # LÆ°u káº¿t quáº£ test vÃ o JSON
    with open("models/test_results.json", "w") as f:
        json.dump(final_test_acc_dict, f, indent=4)

    print("âœ… Káº¿t quáº£ test tá»«ng nhÃ£n:")
    for label, acc in final_test_acc_dict.items():
        print(f"ğŸ”¹ {label}: {acc:.2f}%")

if __name__ == '__main__':
    main()
